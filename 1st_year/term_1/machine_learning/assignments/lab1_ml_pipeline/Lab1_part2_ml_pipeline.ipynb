{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_x-6TwoesXV",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-86e0de040aac317a",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "# Lab assignment â„–1, part 2\n",
        "\n",
        "This lab assignment consists of several parts. You are supposed to make some transformations, train some models, estimate the quality of the models and explain your results.\n",
        "\n",
        "Several comments:\n",
        "* Don't hesitate to ask questions, it's a good practice.\n",
        "* No private/public sharing, please. The copied assignments will be graded with 0 points.\n",
        "* Blocks of this lab will be graded separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do05JVstesXa"
      },
      "source": [
        "__*This is the second part of the assignment. First and third parts are waiting for you in the same directory.*__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJPidCi7esXb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-512ba712fc0fc065",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "## Part 2. Data preprocessing, model training and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-uDGI0jesXb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b656a4266174b009",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "### 1. Reading the data\n",
        "Today we work with the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), describing different cars for multiclass ($k=4$) classification problem. The data is available below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OScubvUkesXc"
      },
      "outputs": [],
      "source": [
        "# If on colab, uncomment the following lines\n",
        "\n",
        "# ! wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_made/homeworks/lab01_ml_pipeline/car_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HY24tJ4xesXd",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-eebac6bfdf73d0bc",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "outputId": "7ad9c2e3-c9a6-4bac-e2d7-5099d3555102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(846, 19) (846,)\n",
            "(549, 19) (549,) (297, 19) (297,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
        "data = dataset[:, :-1].astype(int)\n",
        "target = dataset[:, -1]\n",
        "\n",
        "print(data.shape, target.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqaHsJxYesXe",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-88b1a0f688568f2c",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "To get some insights about the dataset, `pandas` might be used. The `train` part is transformed to `pd.DataFrame` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H52brImdesXf",
        "outputId": "d0254b37-1b10-433a-945c-52393b4279de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842</td>\n",
              "      <td>89</td>\n",
              "      <td>46</td>\n",
              "      <td>84</td>\n",
              "      <td>163</td>\n",
              "      <td>66</td>\n",
              "      <td>11</td>\n",
              "      <td>159</td>\n",
              "      <td>43</td>\n",
              "      <td>20</td>\n",
              "      <td>159</td>\n",
              "      <td>173</td>\n",
              "      <td>368</td>\n",
              "      <td>176</td>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>186</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45</td>\n",
              "      <td>93</td>\n",
              "      <td>46</td>\n",
              "      <td>82</td>\n",
              "      <td>145</td>\n",
              "      <td>58</td>\n",
              "      <td>11</td>\n",
              "      <td>159</td>\n",
              "      <td>43</td>\n",
              "      <td>20</td>\n",
              "      <td>160</td>\n",
              "      <td>180</td>\n",
              "      <td>371</td>\n",
              "      <td>189</td>\n",
              "      <td>77</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>183</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>264</td>\n",
              "      <td>103</td>\n",
              "      <td>49</td>\n",
              "      <td>100</td>\n",
              "      <td>194</td>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>185</td>\n",
              "      <td>35</td>\n",
              "      <td>22</td>\n",
              "      <td>160</td>\n",
              "      <td>202</td>\n",
              "      <td>518</td>\n",
              "      <td>178</td>\n",
              "      <td>62</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>198</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67</td>\n",
              "      <td>98</td>\n",
              "      <td>55</td>\n",
              "      <td>101</td>\n",
              "      <td>219</td>\n",
              "      <td>69</td>\n",
              "      <td>11</td>\n",
              "      <td>225</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>178</td>\n",
              "      <td>231</td>\n",
              "      <td>748</td>\n",
              "      <td>216</td>\n",
              "      <td>74</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>187</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>119</td>\n",
              "      <td>54</td>\n",
              "      <td>106</td>\n",
              "      <td>220</td>\n",
              "      <td>65</td>\n",
              "      <td>12</td>\n",
              "      <td>213</td>\n",
              "      <td>31</td>\n",
              "      <td>24</td>\n",
              "      <td>167</td>\n",
              "      <td>223</td>\n",
              "      <td>675</td>\n",
              "      <td>232</td>\n",
              "      <td>66</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>285</td>\n",
              "      <td>89</td>\n",
              "      <td>48</td>\n",
              "      <td>85</td>\n",
              "      <td>189</td>\n",
              "      <td>64</td>\n",
              "      <td>8</td>\n",
              "      <td>169</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "      <td>153</td>\n",
              "      <td>188</td>\n",
              "      <td>427</td>\n",
              "      <td>190</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>195</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>344</td>\n",
              "      <td>99</td>\n",
              "      <td>55</td>\n",
              "      <td>101</td>\n",
              "      <td>219</td>\n",
              "      <td>68</td>\n",
              "      <td>10</td>\n",
              "      <td>224</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>178</td>\n",
              "      <td>228</td>\n",
              "      <td>737</td>\n",
              "      <td>213</td>\n",
              "      <td>74</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>187</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>675</td>\n",
              "      <td>100</td>\n",
              "      <td>58</td>\n",
              "      <td>109</td>\n",
              "      <td>230</td>\n",
              "      <td>70</td>\n",
              "      <td>11</td>\n",
              "      <td>226</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>182</td>\n",
              "      <td>234</td>\n",
              "      <td>752</td>\n",
              "      <td>207</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>187</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>318</td>\n",
              "      <td>89</td>\n",
              "      <td>37</td>\n",
              "      <td>51</td>\n",
              "      <td>111</td>\n",
              "      <td>54</td>\n",
              "      <td>5</td>\n",
              "      <td>120</td>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>127</td>\n",
              "      <td>138</td>\n",
              "      <td>213</td>\n",
              "      <td>147</td>\n",
              "      <td>82</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>181</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>272</td>\n",
              "      <td>91</td>\n",
              "      <td>43</td>\n",
              "      <td>88</td>\n",
              "      <td>157</td>\n",
              "      <td>61</td>\n",
              "      <td>9</td>\n",
              "      <td>149</td>\n",
              "      <td>45</td>\n",
              "      <td>19</td>\n",
              "      <td>157</td>\n",
              "      <td>165</td>\n",
              "      <td>326</td>\n",
              "      <td>140</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>197</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>217</td>\n",
              "      <td>104</td>\n",
              "      <td>57</td>\n",
              "      <td>103</td>\n",
              "      <td>216</td>\n",
              "      <td>69</td>\n",
              "      <td>11</td>\n",
              "      <td>219</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>176</td>\n",
              "      <td>228</td>\n",
              "      <td>708</td>\n",
              "      <td>219</td>\n",
              "      <td>73</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>186</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>313</td>\n",
              "      <td>96</td>\n",
              "      <td>52</td>\n",
              "      <td>104</td>\n",
              "      <td>222</td>\n",
              "      <td>67</td>\n",
              "      <td>9</td>\n",
              "      <td>198</td>\n",
              "      <td>33</td>\n",
              "      <td>23</td>\n",
              "      <td>163</td>\n",
              "      <td>217</td>\n",
              "      <td>589</td>\n",
              "      <td>226</td>\n",
              "      <td>67</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>192</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>238</td>\n",
              "      <td>100</td>\n",
              "      <td>55</td>\n",
              "      <td>101</td>\n",
              "      <td>189</td>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>222</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>177</td>\n",
              "      <td>225</td>\n",
              "      <td>731</td>\n",
              "      <td>211</td>\n",
              "      <td>71</td>\n",
              "      <td>7</td>\n",
              "      <td>17</td>\n",
              "      <td>188</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>88</td>\n",
              "      <td>91</td>\n",
              "      <td>42</td>\n",
              "      <td>84</td>\n",
              "      <td>209</td>\n",
              "      <td>75</td>\n",
              "      <td>6</td>\n",
              "      <td>171</td>\n",
              "      <td>38</td>\n",
              "      <td>20</td>\n",
              "      <td>138</td>\n",
              "      <td>189</td>\n",
              "      <td>446</td>\n",
              "      <td>161</td>\n",
              "      <td>69</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>196</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>577</td>\n",
              "      <td>99</td>\n",
              "      <td>54</td>\n",
              "      <td>100</td>\n",
              "      <td>199</td>\n",
              "      <td>62</td>\n",
              "      <td>9</td>\n",
              "      <td>200</td>\n",
              "      <td>33</td>\n",
              "      <td>23</td>\n",
              "      <td>166</td>\n",
              "      <td>222</td>\n",
              "      <td>600</td>\n",
              "      <td>241</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>189</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1   2    3    4   5   6    7   8   9    10   11   12   13  14  15  \\\n",
              "0   842   89  46   84  163  66  11  159  43  20  159  173  368  176  72   1   \n",
              "1    45   93  46   82  145  58  11  159  43  20  160  180  371  189  77   2   \n",
              "2   264  103  49  100  194  60  10  185  35  22  160  202  518  178  62  13   \n",
              "3    67   98  55  101  219  69  11  225  30  25  178  231  748  216  74   6   \n",
              "4    44  119  54  106  220  65  12  213  31  24  167  223  675  232  66  20   \n",
              "5   285   89  48   85  189  64   8  169  39  20  153  188  427  190  64  16   \n",
              "6   344   99  55  101  219  68  10  224  30  25  178  228  737  213  74  11   \n",
              "7   675  100  58  109  230  70  11  226  30  25  182  234  752  207  72   0   \n",
              "8   318   89  37   51  111  54   5  120  56  17  127  138  213  147  82   7   \n",
              "9   272   91  43   88  157  61   9  149  45  19  157  165  326  140  64   1   \n",
              "10  217  104  57  103  216  69  11  219  30  25  176  228  708  219  73   4   \n",
              "11  313   96  52  104  222  67   9  198  33  23  163  217  589  226  67  12   \n",
              "12  238  100  55  101  189  57  10  222  30  25  177  225  731  211  71   7   \n",
              "13   88   91  42   84  209  75   6  171  38  20  138  189  446  161  69   3   \n",
              "14  577   99  54  100  199  62   9  200  33  23  166  222  600  241  70   2   \n",
              "\n",
              "    16   17   18  \n",
              "0   20  186  197  \n",
              "1    4  183  194  \n",
              "2    8  198  208  \n",
              "3   14  187  195  \n",
              "4    1  192  202  \n",
              "5    5  195  201  \n",
              "6   20  187  196  \n",
              "7   13  187  198  \n",
              "8    4  181  183  \n",
              "9   26  197  207  \n",
              "10   3  186  196  \n",
              "11  20  192  201  \n",
              "12  17  188  197  \n",
              "13  12  196  201  \n",
              "14   7  189  198  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_pd = pd.DataFrame(X_train)\n",
        "\n",
        "# First 15 rows of our dataset.\n",
        "X_train_pd.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuqFyHQDesXg",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-98e7d91d77d65fcf",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "Methods `describe` and `info` deliver some useful information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0-xUTILIesXh",
        "outputId": "91169bdf-0dd7-46d1-a864-d7edca47e86d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>417.555556</td>\n",
              "      <td>93.431694</td>\n",
              "      <td>44.786885</td>\n",
              "      <td>81.581056</td>\n",
              "      <td>168.278689</td>\n",
              "      <td>61.810565</td>\n",
              "      <td>8.581056</td>\n",
              "      <td>167.837887</td>\n",
              "      <td>41.194900</td>\n",
              "      <td>20.517304</td>\n",
              "      <td>148.012750</td>\n",
              "      <td>187.961749</td>\n",
              "      <td>434.775956</td>\n",
              "      <td>174.480874</td>\n",
              "      <td>72.653916</td>\n",
              "      <td>6.211293</td>\n",
              "      <td>12.234973</td>\n",
              "      <td>188.717668</td>\n",
              "      <td>195.389800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>246.538672</td>\n",
              "      <td>8.262426</td>\n",
              "      <td>6.146043</td>\n",
              "      <td>15.722250</td>\n",
              "      <td>34.311805</td>\n",
              "      <td>8.517297</td>\n",
              "      <td>4.736418</td>\n",
              "      <td>33.269431</td>\n",
              "      <td>7.816339</td>\n",
              "      <td>2.586844</td>\n",
              "      <td>14.398329</td>\n",
              "      <td>31.499513</td>\n",
              "      <td>176.377382</td>\n",
              "      <td>32.342517</td>\n",
              "      <td>7.460632</td>\n",
              "      <td>4.819647</td>\n",
              "      <td>8.803687</td>\n",
              "      <td>6.104509</td>\n",
              "      <td>7.372342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>191.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>176.000000</td>\n",
              "      <td>181.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>208.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>167.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>190.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>414.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>362.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>188.000000</td>\n",
              "      <td>196.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>628.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>194.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>217.000000</td>\n",
              "      <td>597.000000</td>\n",
              "      <td>198.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>193.000000</td>\n",
              "      <td>201.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>845.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>333.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>265.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>188.000000</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>1018.000000</td>\n",
              "      <td>268.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>206.000000</td>\n",
              "      <td>211.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0           1           2           3           4           5   \\\n",
              "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
              "mean   417.555556   93.431694   44.786885   81.581056  168.278689   61.810565   \n",
              "std    246.538672    8.262426    6.146043   15.722250   34.311805    8.517297   \n",
              "min      0.000000   73.000000   34.000000   42.000000  109.000000   47.000000   \n",
              "25%    208.000000   87.000000   40.000000   70.000000  140.000000   57.000000   \n",
              "50%    414.000000   92.000000   44.000000   78.000000  165.000000   61.000000   \n",
              "75%    628.000000   99.000000   49.000000   96.000000  194.000000   65.000000   \n",
              "max    845.000000  119.000000   59.000000  112.000000  333.000000  138.000000   \n",
              "\n",
              "               6           7           8           9           10          11  \\\n",
              "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
              "mean     8.581056  167.837887   41.194900   20.517304  148.012750  187.961749   \n",
              "std      4.736418   33.269431    7.816339    2.586844   14.398329   31.499513   \n",
              "min      3.000000  114.000000   26.000000   17.000000  118.000000  131.000000   \n",
              "25%      6.000000  145.000000   33.000000   19.000000  137.000000  167.000000   \n",
              "50%      8.000000  156.000000   43.000000   20.000000  146.000000  178.000000   \n",
              "75%     10.000000  199.000000   46.000000   23.000000  159.000000  217.000000   \n",
              "max     52.000000  265.000000   59.000000   29.000000  188.000000  320.000000   \n",
              "\n",
              "                12          13          14          15          16  \\\n",
              "count   549.000000  549.000000  549.000000  549.000000  549.000000   \n",
              "mean    434.775956  174.480874   72.653916    6.211293   12.234973   \n",
              "std     176.377382   32.342517    7.460632    4.819647    8.803687   \n",
              "min     191.000000  109.000000   61.000000    0.000000    0.000000   \n",
              "25%     314.000000  148.000000   68.000000    2.000000    5.000000   \n",
              "50%     362.000000  174.000000   72.000000    5.000000   11.000000   \n",
              "75%     597.000000  198.000000   76.000000    9.000000   17.000000   \n",
              "max    1018.000000  268.000000  135.000000   22.000000   39.000000   \n",
              "\n",
              "               17          18  \n",
              "count  549.000000  549.000000  \n",
              "mean   188.717668  195.389800  \n",
              "std      6.104509    7.372342  \n",
              "min    176.000000  181.000000  \n",
              "25%    184.000000  190.000000  \n",
              "50%    188.000000  196.000000  \n",
              "75%    193.000000  201.000000  \n",
              "max    206.000000  211.000000  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_pd.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2k9uoem3esXh",
        "outputId": "7d0026ec-8693-478c-b987-e193703087b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 549 entries, 0 to 548\n",
            "Data columns (total 19 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   0       549 non-null    int32\n",
            " 1   1       549 non-null    int32\n",
            " 2   2       549 non-null    int32\n",
            " 3   3       549 non-null    int32\n",
            " 4   4       549 non-null    int32\n",
            " 5   5       549 non-null    int32\n",
            " 6   6       549 non-null    int32\n",
            " 7   7       549 non-null    int32\n",
            " 8   8       549 non-null    int32\n",
            " 9   9       549 non-null    int32\n",
            " 10  10      549 non-null    int32\n",
            " 11  11      549 non-null    int32\n",
            " 12  12      549 non-null    int32\n",
            " 13  13      549 non-null    int32\n",
            " 14  14      549 non-null    int32\n",
            " 15  15      549 non-null    int32\n",
            " 16  16      549 non-null    int32\n",
            " 17  17      549 non-null    int32\n",
            " 18  18      549 non-null    int32\n",
            "dtypes: int32(19)\n",
            "memory usage: 40.9 KB\n"
          ]
        }
      ],
      "source": [
        "X_train_pd.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_qJkRQsesXi",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-be844269be69c387",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "### 2. Machine Learning pipeline\n",
        "Here you are supposed to perform the desired transformations. Please, explain your results briefly after each task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWW6Y59yesXi"
      },
      "source": [
        "#### 2.0. Data preprocessing\n",
        "* Make some transformations of the dataset (if necessary). Briefly explain the transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb3m8TyKesXj",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-a1514aa189a49fca",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcOldPlcesXj"
      },
      "source": [
        "#### 2.1. Basic logistic regression\n",
        "* Find optimal hyperparameters for logistic regression with cross-validation on the `train` data (small grid/random search is enough, no need to find the *best* parameters).\n",
        "\n",
        "* Estimate the model quality with `f1` and `accuracy` scores.\n",
        "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
        "\n",
        "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` `tol=1e-3` and ` max_iter=500`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7X7gVxmesXj",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-1dd5ad5d0845cbbb",
          "locked": false,
          "points": 5,
          "schema_version": 2,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U17oWX8OesXk"
      },
      "outputs": [],
      "source": [
        "# You might use this command to install scikit-plot. \n",
        "# Warning, if you a running locally, don't call pip from within jupyter, call it from terminal in the corresponding \n",
        "# virtual environment instead\n",
        "\n",
        "# ! pip install scikit-plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iJBy5UlesXk"
      },
      "source": [
        "#### 2.2. PCA: explained variance plot\n",
        "* Apply the PCA to the train part of the data. Build the explaided variance plot. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L4g9o6ResXk",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-c6c614740bce090e",
          "locked": false,
          "points": 10,
          "schema_version": 2,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCfrXTb1esXl",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0c1fe666f52fe53c",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "#### 2.3. PCA trasformation\n",
        "* Select the appropriate number of components. Briefly explain your choice. Should you normalize the data?\n",
        "\n",
        "*Use `fit` and `transform` methods to transform the `train` and `test` parts.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFmCfTjZesXl",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-96ab18d96473ef71",
          "locked": false,
          "points": 5,
          "schema_version": 2,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELEuWZSUesXl"
      },
      "source": [
        "**Note: From this point `sklearn` [Pipeline](https://scikit-learn.org/stable/modules/compose.html) might be useful to perform transformations on the data. Refer to the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for more information.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LV3jDEEesXl",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d28b58a35c94e988",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "#### 2.4. Logistic regression on PCA-preprocessed data.\n",
        "* Find optimal hyperparameters for logistic regression with cross-validation on the transformed by PCA `train` data.\n",
        "\n",
        "* Estimate the model quality with `f1` and `accuracy` scores.\n",
        "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
        "\n",
        "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` and `tol=1e-3`*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn1iSzaDesXm",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-12d53ea45258fa82",
          "locked": false,
          "points": 5,
          "schema_version": 2,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbSHk8EFesXm",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4fbf16c64076e139",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "#### 2.5. Decision tree\n",
        "* Now train a desicion tree on the same data. Find optimal tree depth (`max_depth`) using cross-validation.\n",
        "\n",
        "* Measure the model quality using the same metrics you used above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhdGReNfesXm",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-748ed20b51c67fab",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hj5kLvDesXm",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9eadd4d8a03ae67a",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "#### 2.6. Bagging.\n",
        "Here starts the ensembling part.\n",
        "\n",
        "First we will use the __Bagging__ approach. Build an ensemble of $N$ algorithms varying N from $N_{min}=2$ to $N_{max}=100$ (with step 5).\n",
        "\n",
        "We will build two ensembles: of logistic regressions and of decision trees.\n",
        "\n",
        "*Comment: each ensemble should be constructed from models of the same family, so logistic regressions should not be mixed up with decision trees.*\n",
        "\n",
        "\n",
        "*Hint 1: To build a __Bagging__ ensebmle varying the ensemble size efficiently you might generate $N_{max}$ subsets of `train` data (of the same size as the original dataset) using bootstrap procedure once. Then you train a new instance of logistic regression/decision tree with optimal hyperparameters you estimated before on each subset (so you train it from scratch). Finally, to get an ensemble of $N$ models you average the $N$ out of $N_{max}$ models predictions.*\n",
        "\n",
        "*Hint 2: sklearn might help you with this taks. Some appropriate function/class might be out there.*\n",
        "\n",
        "* Plot `f1` and `accuracy` scores plots w.r.t. the size of the ensemble.\n",
        "\n",
        "* Briefly analyse the plot. What is the optimal number of algorithms? Explain your answer.\n",
        "\n",
        "* How do you think, are the hyperparameters for the decision trees you found in 2.5 optimal for trees used in ensemble? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEg-a2mcesXn",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-8fc95a2b206bdae1",
          "locked": false,
          "points": 35,
          "schema_version": 2,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eOeYTqnesXn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tJArJV1esXn",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-241b7691ab44cbfb",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "#### 2.7. Random Forest\n",
        "Now we will work with the Random Forest (its `sklearn` implementation).\n",
        "\n",
        "* * Plot `f1` and `accuracy` scores plots w.r.t. the number of trees in Random Forest.\n",
        "\n",
        "* What is the optimal number of trees you've got? Is it different from the optimal number of logistic regressions/decision trees in 2.6? Explain the results briefly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWKv96N2esXn",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-888755d0f3d91620",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3zro087esXn",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-99191c0852538d4d",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      },
      "source": [
        "#### 2.8. Learning curve\n",
        "Your goal is to estimate, how does the model behaviour change with the increase of the `train` dataset size.\n",
        "\n",
        "* Split the training data into 10 equal (almost) parts. Then train the models from above (Logistic regression, Desicion Tree, Random Forest) with optimal hyperparameters you have selected on 1 part, 2 parts (combined, so the train size in increased by 2 times), 3 parts and so on.\n",
        "\n",
        "* Build a plot of `accuracy` and `f1` scores on `test` part, varying the `train` dataset size (so the axes will be score - dataset size.\n",
        "\n",
        "* Analyse the final plot. Can you make any conlusions using it? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqWBYbb8esXn",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-e39bc7e7dff61ff9",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "7abe41bf88626c8179a12d706309ac1665b0164ec3bd4c11d7418ed9f0904ed3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
