{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you submit this notebook, make sure everything runs as expected in the local test cases. \n",
    "Please, paste the solution to the designed cell and do not change anything else.\n",
    "\n",
    "Also, please, leave your first and last names below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstName = \"Aleksey\"\n",
    "LastName = \"Ryabykin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.spatial.distance import cdist # You can use this for rbf kernel\n",
    "\n",
    "import unittest\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dfd5431f2494f8f56c119aaae6805ca",
     "grade": false,
     "grade_id": "cell-7bfbe050819ecfac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def rbf(x_1, x_2, sigma=1.):\n",
    "    '''Computes rbf kernel for batches of objects\n",
    "\n",
    "    Args:\n",
    "        x_1: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n",
    "        x_2: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n",
    "    Returns:\n",
    "        kernel function values for all pairs of samples from x_1 and x_2\n",
    "        torch.tensor of type torch.float32 shaped `(#samples_1, #samples_2)`\n",
    "    '''\n",
    "    size = (x_1.size(0), x_2.size(0), x_1.size(1))\n",
    "    distances = torch.exp(-(torch.pow(\n",
    "        (x_1.unsqueeze(1).expand(size) \n",
    "        - x_2.unsqueeze(0).expand(size)), 2).sum(2)) / (2 * sigma**2))\n",
    "    ### YOUR CODE HERE\n",
    "    return torch.Tensor(distances).type(torch.float32)\n",
    "\n",
    "def hinge_loss(scores, labels):\n",
    "    '''Mean loss for batch of objects\n",
    "    '''\n",
    "    assert len(scores.shape) == 1\n",
    "    assert len(labels.shape) == 1\n",
    "    return torch.clamp((1 - scores * labels), 0).mean()### YOUR CODE HERE\n",
    "\n",
    "\n",
    "class SVM(BaseEstimator, ClassifierMixin):\n",
    "    @staticmethod\n",
    "    def linear(x_1, x_2):\n",
    "        '''Computes linear kernel for batches of objects\n",
    "        \n",
    "        Args:\n",
    "            x_1: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n",
    "            x_2: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n",
    "        Returns:\n",
    "            kernel function values for all pairs of samples from x_1 and x_2\n",
    "            torch.tensor shaped `(#samples_1, #samples_2)` of type torch.float32\n",
    "        '''\n",
    "        return x_1 @ x_2.T### YOUR CODE HERE\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float=1e-3,\n",
    "        epochs: int=2,\n",
    "        batch_size: int=64,\n",
    "        lmbd: float=1e-4,\n",
    "        kernel_function=None,\n",
    "        verbose: bool=False,\n",
    "    ):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lmbd = lmbd\n",
    "        self.kernel_function = kernel_function or SVM.linear\n",
    "        self.verbose = verbose\n",
    "        self.fitted = False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'SVM model, fitted: {self.fitted}'\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        assert (np.abs(Y) == 1).all()\n",
    "        n_obj = len(X)\n",
    "        X, Y = torch.FloatTensor(X), torch.FloatTensor(Y)\n",
    "        K = self.kernel_function(X, X).float()\n",
    "\n",
    "        self.betas = torch.full((n_obj, 1), fill_value=0.001, dtype=X.dtype, requires_grad=True)\n",
    "        self.bias = torch.zeros(1, requires_grad=True) # I've also add bias to the model\n",
    "        \n",
    "        optimizer = optim.SGD((self.betas, self.bias), lr=self.lr)\n",
    "        for epoch in range(self.epochs):\n",
    "            perm = torch.randperm(n_obj)  # Generate a set of random numbers of length: sample size\n",
    "            sum_loss = 0.                 # Loss for each epoch\n",
    "            for i in range(0, n_obj, self.batch_size):\n",
    "                batch_inds = perm[i:i + self.batch_size]\n",
    "                x_batch = X[batch_inds]   # Pick random samples by iterating over random permutation\n",
    "                y_batch = Y[batch_inds]   # Pick the correlating class\n",
    "                k_batch = K[batch_inds]\n",
    "                \n",
    "                optimizer.zero_grad()     # Manually zero the gradient buffers of the optimizer\n",
    "                \n",
    "                preds = k_batch @ self.betas - self.bias### YOUR CODE HERE # get the matrix product using SVM parameters: self.betas and self.bias\n",
    "                preds = preds.flatten()\n",
    "                loss = self.lmbd * self.betas[batch_inds].T @ k_batch @ self.betas + hinge_loss(preds, y_batch)\n",
    "                loss.backward()           # Backpropagation\n",
    "                optimizer.step()          # Optimize and adjust weights\n",
    "\n",
    "                sum_loss += loss.item()   # Add the loss\n",
    "\n",
    "            if self.verbose: print(\"Epoch \" + str(epoch) + \", Loss: \" + str(sum_loss / self.batch_size))\n",
    "\n",
    "        self.X = X\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict_scores(self, batch):\n",
    "        with torch.no_grad():\n",
    "            batch = torch.from_numpy(batch).float()\n",
    "            K = self.kernel_function(batch, self.X)\n",
    "            # compute the margin values for every object in the batch\n",
    "            return (K @ self.betas - self.bias).flatten()### YOUR CODE HERE\n",
    "\n",
    "    def predict(self, batch):\n",
    "        scores = self.predict_scores(batch)\n",
    "        answers = np.full(len(batch), -1, dtype=np.int64)\n",
    "        answers[scores > 0] = 1\n",
    "        return answers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 0: Initialization (0.01 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f87629291b35b31fb9f91f4a61c7e28",
     "grade": true,
     "grade_id": "cell-68578dd758ce6174",
     "locked": true,
     "points": 0.01,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# do not change this cell\n",
    "from sklearn.datasets import make_circles\n",
    "X, y = make_circles(150, factor=.1, noise=.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: SVM accuracy (0.69 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e3c1fad99095246f9aab0334f14512a",
     "grade": true,
     "grade_id": "cell-1759990cd7cea5ce",
     "locked": true,
     "points": 0.69,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_test, y_test = X[100:], y[100:]\n",
    "X, y = X[:100], y[:100]\n",
    "y[y==0] = -1 # for convenience with formulas\n",
    "y_test[y_test==0] = -1\n",
    "clf = SVM(epochs=150, lr=0.1, batch_size=20, verbose=False, kernel_function=rbf)\n",
    "clf.fit(X, y)\n",
    "pred = clf.predict(X_test)\n",
    "assert accuracy_score(y_test, pred) > 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Kernel (0.3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a296d1662f5027b9b8727cd724f19ab5",
     "grade": true,
     "grade_id": "cell-a92ec82e4098bdd2",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (np.allclose(rbf(X_kernel, X_kernel).detach().cpu().numpy(), np.array([[1.0000e+00, 2.2897e-11],[2.2897e-11, 1.0000e+00]])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "babd8c75c98cd8447c0227b571d78cab2b67eeb0619e306883203ef76c1b8d2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
